{
  "version": "1",
  "metadata": {
    "marimo_version": "0.18.0"
  },
  "cells": [
    {
      "id": "Hbol",
      "code_hash": "9f372007a72b2ae0cb03fea172ecd380",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"quick-start\">Quick Start</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "MJUe",
      "code_hash": "ee01cc4a4fd8bce329dc561dc396a48b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The <code>ssms</code> package serves two purposes.</span>\n<ol>\n<li>Easy access to <em>fast simulators of sequential sampling models</em></li>\n<li>Support infrastructure to construct training data for various approaches to likelihood / posterior amortization</li>\n</ol>\n<span class=\"paragraph\">We provide two minimal examples here to illustrate how to use each of the two capabilities.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vblA",
      "code_hash": "4c63e573bf7e6a6f58f48284fb97ec28",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h4 id=\"install\">Install</h4>\n<span class=\"paragraph\">Let's start with <em>installing</em> the <code>ssms</code> package.</span>\n<span class=\"paragraph\">You can do so by typing,</span>\n<span class=\"paragraph\"><code>pip install ssm-simulators</code></span>\n<span class=\"paragraph\">in your terminal.</span>\n<span class=\"paragraph\">Below you find a basic tutorial on how to use the package.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "bkHC",
      "code_hash": "b9220a4447f0f22ec3bb84c7174dcbbc",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h4 id=\"tutorial\">Tutorial</h4></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "PKri",
      "code_hash": "bf39e21b307ed35c0a9ebed1aba92f53",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h4 id=\"using-the-simulators\">Using the Simulators</h4>\n<span class=\"paragraph\">Let's start with using the basic simulators.\nYou access the main simulators through the  <code>ssms.basic_simulators.simulator.simulator()</code> function.</span>\n<span class=\"paragraph\">To get an idea about the models included in <code>ssms</code>, use the <code>config</code> module.\nThe central dictionary with metadata about included models sits in <code>ssms.config.model_config</code>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "BYtC",
      "code_hash": "e5503f4e5e7e801de830e4834d153b46",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\"><strong>Note:</strong>\nThe usual structure of these models includes,</span>\n<ul>\n<li>Parameter names (<code>'params'</code>)</li>\n<li>Bounds on the parameters (<code>'param_bounds'</code>)</li>\n<li>A function that defines a boundary for the respective model (<code>'boundary'</code>)</li>\n<li>The number of parameters (<code>'n_params'</code>)</li>\n<li>Defaults for the parameters (<code>'default_params'</code>)</li>\n<li>The number of choices the process can produce (<code>'nchoices'</code>)</li>\n</ul>\n<span class=\"paragraph\">The <code>'hddm_include'</code> key concerns information useful for integration with the <a href=\"https://github.com/hddm-devs/hddm\" rel=\"noopener\" target=\"_blank\">hddm</a> python package, which facilitates hierarchical bayesian inference for sequential sampling models. It is not important for the present tutorial.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Kclp",
      "code_hash": "83af48913e227e449ce7709267de5859",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The output of the simulator is a <code>dictionary</code> with three elements.</span>\n<ol>\n<li><code>rts</code> (array)</li>\n<li><code>choices</code> (array)</li>\n<li><code>metadata</code> (dictionary)</li>\n</ol>\n<span class=\"paragraph\">The <code>metadata</code> includes the named parameters, simulator settings, and more.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "emfo",
      "code_hash": "5da02f947dd5479f258640364f14e27e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h4 id=\"using-the-training-data-generators\">Using the Training Data Generators</h4>\n<span class=\"paragraph\">The training data generators sit on top of the simulator function to turn raw simulations into usable training data for training machine learning algorithms aimed at posterior or likelihood armortization.</span>\n<span class=\"paragraph\">We will use the <code>data_generator</code> class from <code>ssms.dataset_generators</code>. Initializing the <code>data_generator</code> boils down to supplying two configuration dictionaries.</span>\n<ol>\n<li>The <code>generator_config</code>, concerns choices as to what kind of training data one wants to generate.</li>\n<li>The <code>model_config</code> concerns choices with respect to the underlying generative <em>sequential sampling model</em>.</li>\n</ol>\n<span class=\"paragraph\">We will consider a basic example here, concerning data generation to prepare for training <a href=\"https://elifesciences.org/articles/65074\" rel=\"noopener\" target=\"_blank\">LANs</a>.</span>\n<span class=\"paragraph\">Let's start by peeking at an example <code>generator_config</code>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "nWHF",
      "code_hash": "047d42f2d159d735ac6b57ed189a21b3",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">You usually have to make just few changes to this basic configuration dictionary.\nAn example below.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ZHCJ",
      "code_hash": "4862e5a579119c3df5bad15b24bfd148",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Now let's define our corresponding <code>model_config</code>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "qnkX",
      "code_hash": "5172a44f24a4bdfe16eefc9ab27efa0d",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We are now ready to initialize a <code>data_generator</code>, after which we can generate training data using the <code>generate_data_training_uniform</code> function, which will use the hypercube defined by our parameter bounds from the <code>model_config</code> to uniformly generate parameter sets and corresponding simulated datasets.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "DnEU",
      "code_hash": "9f88bdd05b7241c0090dc18260d3a2f8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\"><code>training_data</code> is a dictionary containing four keys:</span>\n<ol>\n<li><code>data</code> the features for <a href=\"https://elifesciences.org/articles/65074\" rel=\"noopener\" target=\"_blank\">LANs</a>, containing vectors of <em>model parameters</em>, as well as <em>rts</em> and <em>choices</em>.</li>\n<li><code>labels</code> which contain approximate likelihood values</li>\n<li><code>generator_config</code>, as defined above</li>\n<li><code>model_config</code>, as defined above</li>\n</ol></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ulZA",
      "code_hash": "c3398764ec6bd75e89f8001e4d4e2a8f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">You can now use this training data for your purposes. If you want to train <a href=\"https://elifesciences.org/articles/65074\" rel=\"noopener\" target=\"_blank\">LANs</a> yourself, you might find the <a href=\"https://github.com/AlexanderFengler/LANfactory\" rel=\"noopener\" target=\"_blank\">LANfactory</a> package helpful.</span>\n<span class=\"paragraph\">You may also simply find the basic simulators provided with the <strong>ssms</strong> package useful, without any desire to use the outputs into training data for amortization purposes.</span>\n<h5 id=\"end\">END</h5></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "lEQa",
      "code_hash": "ec376d72cae4523f51d6bbfbd4b2f9ac",
      "outputs": [],
      "console": []
    },
    {
      "id": "Xref",
      "code_hash": "ea4a3b765c25248a209138a28c450328",
      "outputs": [],
      "console": []
    },
    {
      "id": "SFPL",
      "code_hash": "70f568ce280f4dd3b3909f86f96d8333",
      "outputs": [],
      "console": []
    },
    {
      "id": "RGSE",
      "code_hash": "586c1a53c3214ee23cc9dad1c021c377",
      "outputs": [],
      "console": []
    },
    {
      "id": "Hstk",
      "code_hash": "9c6fdf2198fe82af22781ad80c847324",
      "outputs": [],
      "console": []
    },
    {
      "id": "iLit",
      "code_hash": "90e5cfd6882e44a9c93374b173ab60e5",
      "outputs": [],
      "console": []
    },
    {
      "id": "ROlb",
      "code_hash": "47ba4808a851ea414855513e7b92e0f9",
      "outputs": [],
      "console": []
    },
    {
      "id": "TqIu",
      "code_hash": "71dc159fbe6b446090a568b340112b8e",
      "outputs": [],
      "console": []
    },
    {
      "id": "Vxnm",
      "code_hash": "d205d716771172f53f62e129da859289",
      "outputs": [],
      "console": []
    },
    {
      "id": "ecfG",
      "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e",
      "outputs": [],
      "console": []
    }
  ]
}
